# Medical Representation Learning Papers

| Paper            | Modality and Amount of Data          | Downstreame Task      |  Method         | Code            | Year            |
|------------------|-------------------|---------------------- |-----------------|-----------------|-----------------|
|[Self-Supervised Pre-Training of Swin Transformers for 3D Medical Image Analysis](https://arxiv.org/abs/2111.14791)| CT (5,050)  | Segmentation                  | Self-Supervised            | https://monai.io/research/swin-unetr           | 2022            |
|[Graph-Text Multi-Modal Pre-training for Medical Representation Learning](https://arxiv.org/abs/2203.09994)| Text (-)  | Text Related Prediction                  | Self-Supervised + Supervised            |-          | 2022            |
|[CONTRASTIVE LEARNING OF MEDICAL VISUAL REPRESENTATIONS FROM PAIRED IMAGES AND TEXT](https://arxiv.org/abs/2010.00747)| CXR + Text (-)  | Classification, Retrieval               | Supervised            |-          | 2020            |
|[GLoRIA: A Multimodal Global-Local Representation Learning Framework for Label-efficient Medical Image Recognition](https://openaccess.thecvf.com/content/ICCV2021/papers/Huang_GLoRIA_A_Multimodal_Global-Local_Representation_Learning_Framework_for_Label-Efficient_Medical_ICCV_2021_paper.pdf)| CXR + Text (-)  | Classification               | Supervised            |https://github.com/marshuang80/gloria          | 2021            |

# General Representation Learning Papers
